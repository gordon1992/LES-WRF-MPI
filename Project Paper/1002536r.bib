@article{Anderson1990,
author = {Anderson, Thomas E.},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Anderson - 1990 - The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors.pdf:pdf},
number = {1},
title = {{The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors}},
volume = {1},
year = {1990}
}
@misc{Cerfacs2012,
annote = {Last accessed: 11th November 2014},
author = {Cerfacs, S Valcke},
booktitle = {2nd IS-ENES Workshop on HPC for Climate Models},
doi = {10.5194/gmdd-5-1589-2012.S.},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Cerfacs - 2012 - A review of the coupling technologies used in climate modelling.pdf:pdf},
number = {December 2011},
pages = {1589--1596},
publisher = {2nd IS-ENES Workshop on HPC for Climate Models},
title = {{A review of the coupling technologies used in climate modelling}},
url = {https://verc.enes.org/ISENES2/archive/documents-1/is-enes-2nd-hpc-workshop-presentations-february-2013/session-6-environment-for-hpc/2013\_HPC\_Coupler.pdf},
volume = {4},
year = {2012}
}
@misc{CERFACS2007,
annote = {Last accessed: 11th November 2014},
author = {CERFACS, The OpenPALM Team -},
pages = {1},
title = {{OpenPALM End-point Communications}},
url = {http://www.cerfacs.fr/globc/PALM\_WEB/EN/OVERVIEW/ endpointcommunications.html},
year = {2007}
}
@article{Collins2005,
abstract = {The Earth System Modeling Framework is a component-based architecture$\backslash$nfor developing and assembling climate and related models. A virtual$\backslash$nmachine underlies the component-level constructs in ESMF, providing$\backslash$nboth a foundation for performance portability and mechanisms for$\backslash$nresource allocation and component sequencing.},
author = {Collins, N.},
doi = {10.1177/1094342005056120},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Collins - 2005 - Design and Implementation of Components in the Earth System Modeling Framework.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
keywords = {cli-,framework,high performance computing},
month = aug,
number = {3},
pages = {341--350},
title = {{Design and Implementation of Components in the Earth System Modeling Framework}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342005056120},
volume = {19},
year = {2005}
}
@article{Collins,
author = {Collins, Nancy and Theurich, Gerhard and Deluca, Cecelia and Suarez, Max and Li, Peggy and Hill, Chris},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Collins et al. - 2005 - Design and Implementation of Earth System Modeling Framework Components.pdf:pdf},
journal = {International Journal of High Performance Computing Applications},
number = {3},
pages = {341--350},
title = {{Design and Implementation of Earth System Modeling Framework Components}},
url = {http://www.csm.ornl.gov/~bbd/IJHPCASpecialIssue05/Deluca.pdf},
volume = {19},
year = {2005}
}
@article{Kumar,
author = {{Dozsa, Gabor and Kumar, Sameer and Balaji, Pavan and Buntinas, Darius and Goodell, David and Gropp, William and Ratterman, Joe and Thakur}, Rajeev},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Dozsa, Gabor and Kumar, Sameer and Balaji, Pavan and Buntinas, Darius and Goodell, David and Gropp, William and Ratterman, Joe and Thaku.pdf:pdf},
journal = {EuroMPI'10 Proceedings of the 17th European MPI users' group meeting conference on Recent advances in the message passing interface},
pages = {11--20},
title = {{Enabling Communication Multithreaded MPI Communication on Multicore Petascale Systems}},
year = {2010}
}
@misc{ENES2014,
annote = {Last accessed: 11th November 2014},
author = {ENES},
pages = {1},
title = {{OASIS3-MCT in WRF version 3.6}},
url = {https://verc.enes.org/oasis/news/oasis3-mct-in-wrf-version-3.6},
year = {2014}
}
@misc{ESMF2014,
annote = {Last accessed: 11th November 2014},
author = {ESMF},
title = {{ESMF User Documentation}},
url = {http://www.earthsystemmodeling.org/esmf\_releases/ public/last/ESMF\_usrdoc/node12.html},
year = {2014}
}
@article{Gottschling2012,
abstract = {Sparse linear algebra is a key component of many scientific computations such as computational fluid dynamics, mechanical engineering or the design of new materials to mention only a few. The discretization of complex geometries in unstructured meshes leads to sparse matrices with irregular patterns. Their distribution in turn results in irregular communication patterns within parallel operations. In this paper, we show how sparse linear algebra can be implemented effortless on distributed memory architectures. We demonstrate how simple it is to incorporate advanced partitioning, network topology mapping, and data migration techniques into parallel HPC programs by establishing novel abstractions. For this purpose, we developed a linear algebra library - Parallel Matrix Template Library 4 - based on generic and meta-programming introducing a new paradigm: meta-tuning. The library establishes its own domain-specific language embedded in C++. The simplicity of software development is not paid by lower performance. Moreover, the incorporation of topology mapping demonstrated performance improvements up to 29\%. Â© 2012 IEEE.},
author = {Gottschling, Peter and Hoefler, Torsten},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Gottschling, Hoefler - 2012 - Productive parallel linear algebra programming with unstructured topology adaption.pdf:pdf},
journal = {Proceedings - 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGrid 2012},
keywords = {Parallel linear algebra,domain decomposition,domain-specific embedded languages,generic programming,meta-tuning,topology mapping},
pages = {9--16},
title = {{Productive parallel linear algebra programming with unstructured topology adaption}},
volume = {4},
year = {2012}
}
@misc{Gropp,
annote = {Last accessed: 11th November 2014},
author = {Gropp, William},
booktitle = {19th European MPI Users' Group Meeting, EuroMPI 2012},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Gropp - 2012 - MPI 3 and Beyond Why MPI is Successful and What Challenges it Faces.pdf:pdf},
title = {{MPI 3 and Beyond : Why MPI is Successful and What Challenges it Faces}},
year = {2012}
}
@article{Hoefler2008,
abstract = {Although overlapping communication with computation is an important mechanism for achieving high performance in parallel programs, developing applications that actually achieve good overlap can be difficult. Existing approaches are typically based on manual or compiler-based transformations. This paper presents a pattern and library-based approach to optimizing collective communication in parallel high-performance applications, based on using non-blocking collective operations to enable overlapping of communication and computation. Common communication and computation patterns in iterative SPMD computations are used to motivate the transformations we present. Our approach provides the programmer with the capability to separately optimize communication and computation in an application, while automating the interaction between computation and communication to achieve maximum overlap. Performance results results with two model applications show more than 90\% decrease in communication overhead, resulting in 16\% and 21\% overall performance improvements.$\backslash$n},
author = {Hoefler, Torsten and Gottschling, Peter and Lumsdaine, Andrew},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Hoefler, Gottschling, Lumsdaine - 2008 - Leveraging non-blocking collective communication in high-performance applications.pdf:pdf},
journal = {Proceedings of the twentieth annual symposium on Parallelism in algorithms and architectures - SPAA '08},
pages = {113},
publisher = {ACM Press},
title = {{Leveraging non-blocking collective communication in high-performance applications}},
url = {http://portal.acm.org/citation.cfm?doid=1378533.1378554},
year = {2008}
}
@article{Hoefler2007,
abstract = {Collective operations and non-blocking point-to-point operations have always been part of MPI. Although non-blocking collective operations are an obvious extension to MPI, there have been no comprehensive studies of this functionality. In this paper we present LibNBC, a portable high-performance library for implementing non-blocking collective MPI communication operations. LibNBC provides non-blocking versions of all MPI collective operations, is layered on top of MPI-1, and is portable to nearly all parallel architectures. To measure the performance characteristics of our implementation, we also present a microbenchmark for measuring both latency and overlap of computation and communication. Experimental results demonstrate that the blocking performance of the collective operations in our library is comparable to that of collective operations in other high-performance MPI implementations. Our library introduces a very low overhead between the application and the underlying MPI and thus, in conjunction with the potential to overlap communication with computation, offers the potential for optimizing real-world applications.},
author = {Hoefler, Torsten and Lumsdaine, Andrew and Rehm, Wolfgang},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Hoefler, Lumsdaine, Rehm - 2007 - Implementation and performance analysis of non-blocking collective operations for MPI.pdf:pdf},
isbn = {9781595937643},
journal = {Proceedings of the 2007 ACM/IEEE Conference on Supercomputing (SC '07)},
keywords = {MPI,collective operations,non-blocking collective operations,non-blocking communication,overlap},
title = {{Implementation and performance analysis of non-blocking collective operations for MPI}},
year = {2007}
}
@article{Hoefler2010,
author = {Hoefler, Torsten and Rabenseifner, Rolf and Supinski, Bronis R De and Thakur, Rajeev},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Hoefler et al. - 2011 - The Scalable Process Topology Interface of MPI 2.2.pdf:pdf},
journal = {Concurrency and Computation: Practice \& Experience},
number = {4},
pages = {293--310},
title = {{The Scalable Process Topology Interface of MPI 2.2}},
volume = {23},
year = {2011}
}
@article{Hoefler2010a,
abstract = {Many large-scale parallel programs follow a bulk synchronous parallel (BSP) structure with distinct computation and communication phases. Although the communication phase in such programs may involve all (or large numbers) of the participating processes, the actual communication operations are usually sparse in nature. As a result, communication phases are typically expressed explicitly using point-to-point communication operations or collective operations. We define the dynamic sparse data-exchange (DSDE) problem and derive bounds in the well known LogGP model. While current approaches work well with static applications, they run into limitations as modern applications grow in scale, and as the problems that are being solved become increasingly irregular and dynamic.$\backslash$nTo enable the compact and efficient expression of the communication phase, we develop suitable sparse communication protocols for irregular applications at large scale. We discuss different irregular applications and show the sparsity in the communication for$\backslash$nreal-world input data.We discuss the time and memory complexity of commonly used protocols for the DSDE problem and develop NBXâa novel fast algorithm with constant memory overhead for solving it. Algorithm NBX improves the runtime of a sparse data-$\backslash$nexchange among 8,192 processors on BlueGene/P by a factor of 5.6. In an application study, we show improvements of up to a factor of 28.9 for a parallel breadth first search on 8,192 BlueGene/P processors.$\backslash$n},
author = {Hoefler, Torsten and Siebert, Christian and Lumsdaine, Andrew},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Hoefler, Siebert, Lumsdaine - 2010 - Scalable communication protocols for dynamic sparse data exchange.pdf:pdf},
isbn = {9781605587080},
journal = {ACM SIGPLAN Notices},
keywords = {alltoall,distributed termination,irregular algorithms,nonblocking collective operations,sparse data exchange},
number = {5},
pages = {159},
title = {{Scalable communication protocols for dynamic sparse data exchange}},
volume = {45},
year = {2010}
}
@book{Hutchison,
author = {Hutchison, David and Mitchell, John C},
file = {:Users/gordonreid/Dropbox/University/5th Year/Project/Papers/Gropp - Unknown - MPI 3 and Beyond Why MPI is Successful and What Challenges it Faces What MPI-3 Already !.pdf:pdf},
isbn = {9783642335174},
title = {{Recent Advanced in the Message Passing Interface}}
}
@article{Jacob2005,
author = {Jacob, R.},
doi = {10.1177/1094342005056116},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Jacob - 2005 - M x N Communication and Parallel Interpolation in Community Climate System Model Version 3 Using the Model Coupling Toolk.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = aug,
number = {3},
pages = {293--307},
title = {{M x N Communication and Parallel Interpolation in Community Climate System Model Version 3 Using the Model Coupling Toolkit}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342005056116},
volume = {19},
year = {2005}
}
@article{Jeannot2014,
author = {Jeannot, Emmanuel and Mercier, Guillaume},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Jeannot, Mercier - 2014 - Process Placement in Multicore Clusters Algorithmic Issues and Practical Techniques.pdf:pdf},
journal = {IEEE Transactions on Parallel and Distributed Systems},
number = {4},
pages = {993--1002},
title = {{Process Placement in Multicore Clusters : Algorithmic Issues and Practical Techniques}},
volume = {25},
year = {2014}
}
@misc{Karypis1998,
abstract = {Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445--452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not knownif they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the effectiveness of many different choices for all three phases: coarsening, partition of the coarsest graph, and refinement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition ...},
author = {Karypis, George and Kumar, Vipin},
booktitle = {SIAM Journal on Scientific Computing},
doi = {10.1137/S1064827595287997},
isbn = {SJOCE3000020000001000359000001},
issn = {1064-8275},
pages = {359--392},
title = {{A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs}},
volume = {20},
year = {1998}
}
@inproceedings{Kinbara2010,
abstract = {AWRF-LES computation was carried out for the analysis of a wind environment in the summer in the Nagoya Metropolitan Area, which is located in the central part of Japan.We also performed a single WRF computation with no LES capability and compared the results between the WRF-LES and single WRF computations. The WRF-LES computation predicted a larger magnitude of wind velocity than the single WRF computation. In addition, we are now conducting other WRF-LES computations using the "LES-within-LES" method proposed by Moeng et al. (2007) and using our homemade LES software with an artificial generation method of inflow turbulence.},
author = {Kinbara, Kazuya and Iizuka, Satoru and Kuroki, Misae and Kondo, Akihiko},
booktitle = {The Fifth Symposium Computational Wind Engineering},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Kinbara et al. - 2010 - Merging WRF and LES models for the analysis of a wind environment in an urban area.pdf:pdf},
number = {2007},
title = {{Merging WRF and LES models for the analysis of a wind environment in an urban area}},
year = {2010}
}
@article{Kuinghttons,
annote = {Last accessed: 11th November 2014},
author = {Kuinghttons, Ryan O},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Kuinghttons - Unknown - Conservative Regridding in ESMF.pdf:pdf},
pages = {1--19},
title = {{Conservative Regridding in ESMF}},
url = {http://www.earthsystemmodeling.org/presentations/pres\_1002\_siam\_ryan.pdf}
}
@article{Larson2005,
abstract = {Many problems in science and engineering are best simulated as a set of mutually interacting models, resulting in a coupled or multiphysics model. These models present challenges stemming from their interdisciplinary nature and from their computational and algorithmic complexities. The computational complexity of individual models, combined with the popularity of the distributed-memory parallel programming model used on commodity microprocessor-based clusters, results in a parallel coupling problem when building a coupled model. We define and elucidate this problem and how it results in a set of requirements for software capable of simplifying the construction of parallel coupled models. We describe the package, the Model Coupling Toolkit (MCT), which we have developed to meet these general requirements and the specific requirements of a parallel climate model. We present the MCT programming model with illustrative code examples. We present representative results that measure MCT's scalability, performance portability, and a proxy for coupling overhead.},
author = {Larson, J.},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Larson - 2005 - The Model Coupling Toolkit A New Fortran90 Toolkit for Building Multiphysics Parallel Coupled Models.pdf:pdf},
journal = {International Journal of High Performance Computing Applications},
number = {3},
pages = {277--292},
title = {{The Model Coupling Toolkit: A New Fortran90 Toolkit for Building Multiphysics         Parallel Coupled Models}},
volume = {19},
year = {2005}
}
@misc{Maisonnave,
annote = {Last accessed: 11th November 2014},
author = {Maisonnave, Eric and Caubel, Arnaud},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Maisonnave, Caubel - Unknown - LUCIA, load balancing tool for OASIS coupled systems.pdf:pdf},
title = {{LUCIA, load balancing tool for OASIS coupled systems}},
url = {http://pantar.cerfacs.fr/globc/publication/technicalreport/2014/lucia\_documentation.pdf}
}
@article{Mandel2011,
author = {Mandel, J. and Beezley, J. D. and Kochanski, a. K.},
doi = {10.5194/gmd-4-591-2011},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Mandel, Beezley, Kochanski - 2011 - Coupled atmosphere-wildland fire modeling with WRF 3.3 and SFIRE 2011.pdf:pdf},
issn = {1991-9603},
journal = {Geoscientific Model Development},
month = jul,
number = {3},
pages = {591--610},
title = {{Coupled atmosphere-wildland fire modeling with WRF 3.3 and SFIRE 2011}},
url = {http://www.geosci-model-dev.net/4/591/2011/},
volume = {4},
year = {2011}
}
@article{Mellor-Crummey1991,
author = {Mellor-Crummey, John and Scott, Michael},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Mellor-Crummey, Scott - 1991 - Scalable Reader-Writer Synchronization for Shared-Memory Multiprocessors.pdf:pdf},
pages = {106--113},
title = {{Scalable Reader-Writer Synchronization for Shared-Memory Multiprocessors}},
year = {1991}
}
@article{Michalakes2000,
author = {Michalakes, J and Chen, S and Dudhia, J and Hart, L and Klemp, J and Middlecoff, J and Skamarock, W},
file = {:Users/gordonreid/Dropbox/University/5th Year/Project/Papers/Michalakes et al. - 2000 - Development of a Next Generation Regional Weather Research and Forecast Model.pdf:pdf},
journal = {Proceedings of the Ninth ECMWF Workshop on the Use of High Performance Computing in Meteorology},
pages = {269--276},
title = {{Development of a Next Generation Regional Weather Research and Forecast Model}},
year = {2000}
}
@misc{Michalakes2010,
annote = {Last accessed: 11th November 2014},
author = {Michalakes, John},
booktitle = {WRF Users Workshop},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Michalakes - 2010 - Coupling WRF to Other Models.pdf:pdf},
title = {{Coupling WRF to Other Models}},
url = {http://www2.mmm.ucar.edu/wrf/users/workshops/WS2010/presentations/Tutorials/Coupling WRF Michalakes.pdf},
year = {2010}
}
@article{Mogensen,
author = {Mogensen, Kristian S},
file = {:Users/gordonreid/Dropbox/University/5th Year/Project/Papers/HPC-WS-Mogensen\_0.pdf:pdf},
pages = {1--25},
title = {{The coupled ocean â atmosphere model at ECMWF : overview and technical challenges}}
}
@article{Nakayama2011,
author = {Nakayama, Hiromasa and Takemi, Tetsuya and Nagai, Haruyasu},
doi = {10.1175/2011JAMC2567.1},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Nakayama, Takemi, Nagai - 2011 - LES Analysis of the Aerodynamic Surface Properties for Turbulent Flows over Building Arrays with Variou.pdf:pdf},
issn = {1558-8424},
journal = {Journal of Applied Meteorology and Climatology},
month = aug,
number = {8},
pages = {1692--1712},
title = {{LES Analysis of the Aerodynamic Surface Properties for Turbulent Flows over Building Arrays with Various Geometries}},
url = {http://journals.ametsoc.org/doi/abs/10.1175/2011JAMC2567.1},
volume = {50},
year = {2011}
}
@article{Nakayama2012,
author = {Nakayama, Hiromasa and Takemi, Tetsuya and Nagai, Haruyasu},
doi = {10.1002/asl.377},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Nakayama, Takemi, Nagai - 2012 - Large-eddy simulation of urban boundary-layer flows by generating turbulent inflows from mesoscale mete.pdf:pdf},
issn = {1530261X},
journal = {Atmospheric Science Letters},
keywords = {5 march 2012,7 july 2011,large-eddy simulation,received,revised,turbulent generation,urban boundary layer},
month = jul,
number = {3},
pages = {180--186},
title = {{Large-eddy simulation of urban boundary-layer flows by generating turbulent inflows from mesoscale meteorological simulations}},
url = {http://doi.wiley.com/10.1002/asl.377},
volume = {13},
year = {2012}
}
@article{Nakayama1998,
author = {Nakayama, Hiromasa and Takemi, Tetsuya and Nagai, Haruyasu and Agency, Energy},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Nakayama et al. - 2014 - Coupling of WRF and building-resolving urban CFD models for analysis of strong winds over an urban area.pdf:pdf},
journal = {3rd International Workshop on Nonhydrostatic Numerical Models},
number = {RIKEN AICS, Kobe, Japan},
title = {{Coupling of WRF and building-resolving urban CFD models for analysis of strong winds over an urban area}},
volume = {3},
year = {2014}
}
@article{NorAsilahWatiAbdulHamid2010,
author = {{Nor Asilah Wati Abdul Hamid} and Coddington, P.},
doi = {10.1177/1094342010371106},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Nor Asilah Wati Abdul Hamid, Coddington - 2010 - Comparison of MPI Benchmark Programs on Shared Memory and Distributed Memory Machines (.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
keywords = {mpi benchmarks,parallel computer,performance comparison},
pages = {469--483},
title = {{Comparison of MPI Benchmark Programs on Shared Memory and Distributed Memory Machines (Point-to-Point Communication)}},
volume = {24},
year = {2010}
}
@misc{OASIS3-MCT2013,
annote = {Last accessed: 11th November 2014},
author = {OASIS3-MCT},
title = {{OASIS3-MCT User Guide}},
url = {http://www.cerfacs.fr/oa4web/oasis3-mct/oasis3mct\_UserGuide/ node62.html},
year = {2013}
}
@article{Pan2006,
abstract = {Internet sharing systems aim at federating and utilizing distributed computing resources across the Internet. This paper presents a user-level virtual machine (VM) approach to MPI program execution in an Internet sharing framework. In this approach, the resource consumer has its own operating system running on top of and isolated from, the operating system of the resource provider. We propose an efficient socket virtualization technique to optimize VM network performance. Socket virtualization achieves the same network bandwidth as the physical network. In our LAN environment, it reduces the latency overhead from 112\% (using existing TUN/TAP technique) to 35.6\%. Performance results on MPI benchmarks show that our virtualization technique incurs small overhead compared with the physical host platform, while gaining in return a higher degree of guest isolation and customization. We also describe the key mechanisms that allow the employment of VMs in an existing Internet sharing system},
author = {Pan, Zhelong and Ren, Xiaojuan and Eigenmann, Rudolf and Xu, Dongyan},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Pan et al. - 2006 - Executing MPI programs on virtual machines in an internet sharing system.pdf:pdf},
journal = {20th International Parallel and Distributed Processing Symposium, IPDPS 2006},
title = {{Executing MPI programs on virtual machines in an internet sharing system}},
volume = {2006},
year = {2006}
}
@article{Piacentini2011,
author = {Piacentini, Andrea and Morel, Thierry and Th\'{e}venin, Anthony},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Piacentini, Morel, Th\'{e}venin - 2011 - O-PALM AN OPEN SOURCE DYNAMIC PARALLEL COUPLER.pdf:pdf},
journal = {IV International Conference on Computational Methods for Coupled Problems in Science and Engineering},
keywords = {abstract,been developing the palm,currently used for more,data assimilation,dynamic coupling,graphic user interface,industrial projects ranging from,multi-physics,open-source,operational data,parallel computing,parallel coupler,since 1996 cerfacs has,than 50 research and,which is},
title = {{O-PALM : AN OPEN SOURCE DYNAMIC PARALLEL COUPLER}},
year = {2011}
}
@misc{Polcher2013,
annote = {Last accessed: 11th November 2014},
author = {Polcher, Jan and St\'{e}fanon, Marc},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Polcher, St\'{e}fanon - 2013 - Using OASIS-MCT to couple the ORCHIDEE land surface model.pdf:pdf},
number = {May},
title = {{Using OASIS-MCT to couple the ORCHIDEE land surface model.}},
url = {http://dods.ipsl.jussieu.fr/orchidee/WIKI/Polcher\_OrchideeDays\_OASIS\_Coupling.pdf},
year = {2013}
}
@misc{Programme,
annote = {Last accessed: 11th November 2014},
author = {Programme, Environmental Modelling},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Programme - Unknown - Couplers for linking environmental models Scoping study and potential next steps.pdf:pdf},
title = {{Couplers for linking environmental models: Scoping study and potential next steps}},
url = {http://nora.nerc.ac.uk/508423/1/Couplers rpt FINAL 2014-9-5.pdf}
}
@article{Ramework,
author = {Ramework, S Ystem M Odeling F},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded//Ramework et al. - 2004 - The Architecture of the Earth System Modeling Framework.pdf:pdf},
pages = {18--28},
title = {{The Architecture of the Earth System Modeling Framework}}
}
@article{Ramework2004,
abstract = { The Earth System Modeling Framework (ESMF) project is developing a standard software platform for Earth system models. The standard, which defines a component architecture and a support infrastructure, is being developed under open-software practices. Target applications range from operational numerical weather prediction to climate-system change and predictability studies.},
author = {Ramework, S Ystem M Odeling F and Hill, Chris and DeLuca, Cecelia and Balaji and Suarez, Max and {Da Silva}, Arlindo},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded//Ramework et al. - 2004 - The Architecture of the Earth System Modeling Framework.pdf:pdf},
journal = {Computing in Science and Engineering},
number = {1},
pages = {18--28},
title = {{The Architecture of the Earth System Modeling Framework}},
volume = {6},
year = {2004}
}
@article{Riley2012,
author = {Riley, Graham and Pickles, Stephen and Ham, David},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Riley, Pickles, Ham - 2012 - Towards a Scalable Performance- Portable Software Infrastructure for the Gungho Dynamical Core.pdf:pdf},
journal = {ECMWF Workshop 2012},
title = {{Towards a Scalable Performance- Portable Software Infrastructure for the Gungho Dynamical Core}},
year = {2012}
}
@misc{Sarnowska-upton,
annote = {Last accessed: 11th November 2014},
author = {Sarnowska-upton, Karolina and Grimshaw, Andrew},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Sarnowska-upton, Grimshaw - Unknown - Experiences with MPI Program Migration.pdf:pdf},
keywords = {automated methods,environment configuration,migration,mpi},
number = {3},
title = {{Experiences with MPI Program Migration}},
url = {https://www.cs.virginia.edu/~kas9ud/research/GridLab2012.pdf}
}
@article{StephanFrickenhausReneRedler2001,
author = {{Stephan Frickenhaus, Rene Redler}, Peter Post},
file = {:Users/gordonreid/Dropbox/University/5th Year/Project/Papers/Fri2001b.pdf:pdf},
journal = {World Scientific},
pages = {1--13},
title = {{Parallel Coupling of Regional Atmosphere and Ocean Models}},
year = {2001}
}
@article{Thakur2009a,
abstract = {As parallel systems are commonly being built out of increasingly large multicore chips, application programmers are exploring the use of hybrid programming models combining MPI across nodes and multithreading within a node. Many MPI implementations, however, are just starting to support multithreaded MPI communication, often focussing on correctness first and performance later. As a result, both users and implementers need some measure for evaluating the multithreaded performance of an MPI implementation. In this paper, we propose a number of performance tests that are motivated by typical application scenarios. These tests cover the overhead of providing the MPI\_THREAD\_MULTIPLE level of thread safety for user programs, the amount of concurrency in different threads making MPI calls, the ability to overlap communication with computation, and other features. We present performance results with this test suite on several platforms (Linux cluster, Sun and IBM SMPs) and MPI implementations (MPICH2, Open MPI, IBM, and Sun). ?? 2009 Elsevier B.V.},
author = {Thakur, Rajeev and Gropp, William},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded//Thakur, Gropp - 2009 - Test Suite for Evaluating Performance of Multithreaded MPI Communication.pdf:pdf},
journal = {Parallel Computing},
keywords = {Benchmarks,Message passing interface (MPI),Multithreading,Performance measurement,benchmarks,measurement,message passing interface,mpi,multithreading,performance},
number = {January 2009},
pages = {608--617},
title = {{Test Suite for Evaluating Performance of}},
volume = {35},
year = {2009}
}
@article{Thakur2009,
abstract = {As parallel systems are commonly being built out of increasingly large multicore chips, application programmers are exploring the use of hybrid programming models combining MPI across nodes and multithreading within a node. Many MPI implementations, however, are just starting to support multithreaded MPI communication, often focussing on correctness first and performance later. As a result, both users and implementers need some measure for evaluating the multithreaded performance of an MPI implementation. In this paper, we propose a number of performance tests that are motivated by typical application scenarios. These tests cover the overhead of providing the MPI\_THREAD\_MULTIPLE level of thread safety for user programs, the amount of concurrency in different threads making MPI calls, the ability to overlap communication with computation, and other features. We present performance results with this test suite on several platforms (Linux cluster, Sun and IBM SMPs) and MPI implementations (MPICH2, Open MPI, IBM, and Sun). ?? 2009 Elsevier B.V.},
author = {Thakur, Rajeev and Gropp, William},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded//Thakur, Gropp - 2009 - Test Suite for Evaluating Performance of Multithreaded MPI Communication.pdf:pdf},
journal = {Parallel Computing},
keywords = {Benchmarks,Message passing interface (MPI),Multithreading,Performance measurement,benchmarks,measurement,message passing interface,mpi,multithreading,performance},
number = {January 2009},
pages = {608--617},
title = {{Test Suite for Evaluating Performance of Multithreaded MPI Communication}},
volume = {35},
year = {2009}
}
@misc{Thevenin,
annote = {Last accessed: 11th November 2014},
author = {Thevenin, Anthony},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Thevenin - Unknown - OASIS3-MCT \& Open-PALM 2 open source codes couplers.pdf:pdf},
title = {{OASIS3-MCT \& Open-PALM: 2 open source codes couplers}},
url = {https://www.projet-plume.org/files/oasis\_palm\_envol2012\_janvier-2013\_v2.pdf}
}
@misc{Unidata,
author = {Unidata},
title = {{netCDF}},
url = {http://www.opengeospatial.org/standards/netcdf}
}
@misc{Valcke,
annote = {Last accessed: 11th November 2014},
author = {Valcke, S and Coquart, L},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Valcke, Coquart - Unknown - OASIS3-MCT, a coupler for climate modelling.pdf:pdf},
pages = {1--24},
title = {{OASIS3-MCT, a coupler for climate modelling}},
url = {https://verc.enes.org/ISENES2/documents/presentations/cas2k13/oasis3-mct-a-coupler-for-climate-modelling-s.-valcke}
}
@article{Valcke2013,
author = {Valcke, S.},
doi = {10.5194/gmd-6-373-2013},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Valcke - 2013 - The OASIS3 coupler a European climate modelling community software.pdf:pdf},
issn = {1991-9603},
journal = {Geoscientific Model Development},
month = mar,
number = {2},
pages = {373--388},
title = {{The OASIS3 coupler: a European climate modelling community software}},
url = {http://www.geosci-model-dev.net/6/373/2013/},
volume = {6},
year = {2013}
}
@article{Vanderbauwhede2014,
author = {Vanderbauwhede, Wim},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Vanderbauwhede - 2014 - Model Coupling between the Weather Research and Forecasting Model and the DPRI Large Eddy Simulator for Urban Fl.pdf:pdf},
pages = {1--23},
title = {{Model Coupling between the Weather Research and Forecasting Model and the DPRI Large Eddy Simulator for Urban Flows on GPU-accelerated Multicore Systems}},
year = {2014}
}
@article{Vanderbauwhede2013,
author = {Vanderbauwhede, Wim and Takemi, Tetsuya},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded//Vanderbauwhede, Takemi - 2013 - An Investigation into the Feasibility and Benefits of GPU Multicore Acceleration of the Weather Researc.pdf:pdf},
isbn = {9781479908387},
journal = {Proceedings of the 2013 International Conference on High Performance Computing and Simulation, HPCS 2013},
keywords = {General-Purpose computation on Graphics Processing,Large Scale Scientific Computing,Parallelization of Simulation},
pages = {482--489},
title = {{An Investigation into the Feasibility and Benefits of GPU / Multicore Acceleration of the Weather Research and Forecasting Model}},
year = {2013}
}
@article{Wyszogrodzki2012,
author = {Wyszogrodzki, Andrzej a. and Miao, Shiguang and Chen, Fei},
doi = {10.1016/j.atmosres.2012.07.023},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Wyszogrodzki, Miao, Chen - 2012 - Evaluation of the coupling between mesoscale-WRF and LESâEULAG models for simulating fine-scale urba.pdf:pdf},
issn = {01698095},
journal = {Atmospheric Research},
keywords = {EULAG,Large-eddy simulations (LES),Transport and dispersion (T\& D),Urban area,WRF model},
month = nov,
pages = {324--345},
publisher = {Elsevier B.V.},
title = {{Evaluation of the coupling between mesoscale-WRF and LESâEULAG models for simulating fine-scale urban dispersion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016980951200261X},
volume = {118},
year = {2012}
}
@article{Zhao2013,
abstract = {Many new large-scale applications have emerged recently and become important in areas such as bioinformatics and social networks. These applications are often data-intensive and involve irregular communication patterns and complex operations on remote processes. Active messages have proven effective for parallelizing such nontraditional applications. However, most current active messages frameworks are low-level and system specific, do not efficiently support asynchronous progress, and are not interoperable with two-sided and collective communications. In this paper, we present the design and implementation of an active messages framework inside MPI to provide portability and programmability, and we explore challenges when asynchronously handling active messages and other messages from the network as well as from shared memory. We test our implementation with a set of comprehensive benchmarks. Evaluation results show that our framework has the advantages of overlapping and interoperability, while introducing only a modest overhead.},
author = {Zhao, Xin and Buntinas, Darius and Zounmevo, Judicael and Dinan, James and Goodell, David and Balaji, Pavan and Thakur, Rajeev and Afsahi, Ahmad and Gropp, William},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2013 - Toward asynchronous and MPI-interoperable active messages.pdf:pdf},
journal = {Proceedings - 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2013},
keywords = {Active messages,Asynchronous progress,Data-intensive applications,Interoperable,MPI},
pages = {87--94},
title = {{Toward asynchronous and MPI-interoperable active messages}},
year = {2013}
}
@article{Zhou2006,
author = {Zhou, S. J.},
doi = {10.1002/cpe.912},
file = {:Users/gordonreid/Library/Application Support/Mendeley Desktop/Downloaded/Zhou - 2006 - Coupling climate models with the Earth System Modeling Framework and the Common Component Architecture.pdf:pdf},
issn = {1532-0626},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {climate model,framework,model coupling},
month = feb,
number = {2},
pages = {203--213},
title = {{Coupling climate models with the Earth System Modeling Framework and the Common Component Architecture}},
url = {http://doi.wiley.com/10.1002/cpe.912},
volume = {18},
year = {2006}
}
